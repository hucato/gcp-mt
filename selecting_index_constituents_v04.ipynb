{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f743f8a",
   "metadata": {},
   "source": [
    "# Selecting the Index constituents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc64e7",
   "metadata": {},
   "source": [
    "# Importing and laoding packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97ea933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hagen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import calendar\n",
    "import datetime\n",
    "import nltk\n",
    "import feather\n",
    "import pyarrow\n",
    "import string\n",
    "import xlrd\n",
    "import re\n",
    "import operator \n",
    "import math\n",
    "import sklearn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams \n",
    "from collections import Counter\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114308e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d594c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715dc2c6",
   "metadata": {},
   "source": [
    "# Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca449c43",
   "metadata": {},
   "source": [
    "## Load raw data from Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ad5b4",
   "metadata": {},
   "source": [
    "Careful, this is a large dataset. Skip this part if feather data available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a186e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "# # load all raw cashtag data\n",
    "# path = r'C:\\Users\\hagen\\00_Computing\\data_cashtags' # adjust path\n",
    "# all_files = glob.glob(os.path.join(path, \"*.csv\")) # read all csv files\n",
    "# df_cashtag_data = pd.concat((pd.read_csv(file)\n",
    "#     .assign(ticker = os.path.splitext(os.path.basename(file))[0]) for file in all_files)) # +ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa021fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "# # load all raw hashtag data\n",
    "# path = r'C:\\Users\\hagen\\00_Computing\\data_hashtags' # adjust path\n",
    "# all_files = glob.glob(os.path.join(path, \"*.csv\")) # read all csv files\n",
    "# dtypes = {\"author_id\": int, \"username\": \"string\", \"author_followers\": int, \"author_following\": int, \"author_tweets\": int,\n",
    "#     \"author_listed\": int, \"author_description\": \"string\", \"author_location\": \"string\", \"user_id\": bool, \n",
    "#     \"author_account_age\": \"string\", \"tweet_id\": int, \"text\": \"string\", \"created_at\": \"string\", \n",
    "#     \"retweets\": int, \"replies\": int, \"likes\": int, \"quote_count\": int, \"referenced_tweets\": \"string\", \"media\": \"string\"}\n",
    "# # parse_dates = [\"author_account_age\", \"created_at\"]\n",
    "# df_hashtag_data = pd.concat((pd.read_csv(file, dtype=dtypes, sep=',', header=None, low_memory=False) #, parse_dates = parse_dates)\n",
    "#     .assign(ticker = os.path.splitext(os.path.basename(file))[0]) for file in all_files)) # +ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed231fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes_short = {\"author_followers\": int, \"author_following\": int, \"author_tweets\": int,\n",
    "#     \"author_listed\": int, \"author_verified\": bool, \n",
    "#     \"author_account_age\": str, \"text\": str, \"created_at\": str, \n",
    "#     \"retweets\": int, \"replies\": int, \"likes\": int, \"quote_count\": int}\n",
    "# dtypes = {\"author_id\": \"long\", \"username\": str, \"author_followers\": int, \"author_following\": int, \"author_tweets\": int,\n",
    "#     \"author_listed\": int, \"author_description\": str, \"author_location\": str, \"author_verified\": bool, \n",
    "#     \"author_account_age\": str, \"tweet_id\": \"long\", \"text\": str, \"created_at\": str, \n",
    "#     \"retweets\": int, \"replies\": int, \"likes\": int, \"quote_count\": int, \"referenced_tweets\": str, \"media\": str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d745491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import cashtag data from Excel and save to feather\n",
    "# cashtag_xls = pd.ExcelFile('data_cashtags_all.xlsx')\n",
    "# df_cashtag_data = pd.read_excel(cashtag_xls, dtype=dtypes_short, usecols=\"C:F,I:J,L:Q,T\")\n",
    "# cashtag_pd_filepath = \"./cashtag_pd.ftr\"\n",
    "# df_cashtag_data.to_feather(cashtag_pd_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0c7c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import hashtag data from Excel and save to feather\n",
    "# hashtag_xls = pd.ExcelFile('data_hashtags_combined.xlsx')\n",
    "# hashtag_sheets = hashtag_xls.sheet_names\n",
    "# df_hashtag_data = pd.concat((pd.read_excel(hashtag_xls, sheet_name=s, dtype=dtypes_short, usecols=\"C:F,I:J,L:Q,T\")\n",
    "#                              .assign(ticker=s) for s in hashtag_sheets)\n",
    "#                              , ignore_index=True)\n",
    "# hashtag_pd_filepath = \"./hashtag_pd.ftr\"\n",
    "# df_hashtag_data.to_feather(hashtag_pd_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27125d12",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b07e8",
   "metadata": {},
   "source": [
    "## Tokenization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "b88b5412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define emoticons\n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    "\n",
    "# define other regular expressions\n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r\"(?:\\$+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # cash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    "    \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    # check for alternative \n",
    "    # https://stackoverflow.com/questions/43142710/remove-all-punctuation-from-string-except-if-its-between-digits\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "\n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE) #consider adding cashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "24ccc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_twitter = ['rt', 'via']\n",
    "sw_company = ['ag', 'gmbh', 'se']\n",
    "sw_hype = ['#crypto', '#cryptocurrency', '#decentralisation', '#defi', 'blockchain', '#btc', '#dragonbite', '#bitmart', '#eth', '#nfts', '#nft']\n",
    "sw_other = ['â€™', \"i'm\", 'therefore'] # add larger stop word dictionary than NLTK?\n",
    "sw_spam = ['#swaap', '@swaapcrypto', 'swaap', '#cannabis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "63e49035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for removing stop-words\n",
    "punctuation = list(string.punctuation)\n",
    "stop = stopwords.words('english') + punctuation + sw_twitter + sw_company + sw_crypto + sw_other + sw_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "5a20300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=True):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "7553669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about term.lower()?\n",
    "def tweet_cleaning(tweet):\n",
    "    tweet = preprocess(tweet)\n",
    "    tweet_clean = [term for term in tweet \n",
    "                  if term not in stop and\n",
    "                  not term.startswith(('@', '$', 'http', '_', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))]\n",
    "    # consider removing numbers, and all mentions, incl. #, @, and $, as well as all links\n",
    "    return tweet_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "461a5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # consider removing hashtags\n",
    "# terms_hash = [term for term in list_clean if term.startswith('#')]\n",
    "# # consider removing hashtags\n",
    "# terms_cash = [term for term in list_clean if term.startswith('$')]\n",
    "# # removes all types of tags\n",
    "# terms_only = [term for term in list_clean if not term.startswith(('#', '@', '$'))] \n",
    "# # terms_only = [term for term in preprocess(tweet['text']) \n",
    "# #               if term not in stop and\n",
    "# #               not term.startswith(('#', '@'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6260017",
   "metadata": {},
   "source": [
    "## Choosing data to  work on "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15a428",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "5da7053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read example data with two tickers\n",
    "# ct_short = pd.read_excel('data_cashtags_short.xlsx', usecols=\"C:F,I:J,L:Q,T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a82a0",
   "metadata": {},
   "source": [
    "### Feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "429dad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read actual data from feather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01baf4d8",
   "metadata": {},
   "source": [
    "Cashtag data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "3b398318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cashtag data from feather\n",
    "cashtag_pd_filepath = \"./cashtag_pd.ftr\"\n",
    "ct_cashtags = pd.read_feather(cashtag_pd_filepath, columns=None, use_threads=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc26b9d",
   "metadata": {},
   "source": [
    "Hashtag data -! this is a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "8255071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read hashtag data from feather\n",
    "hashtag_pd_filepath = \"./hashtag_pd.ftr\"\n",
    "ct_hashtags = pd.read_feather(hashtag_pd_filepath, columns=None, use_threads=True)\n",
    "# replace all additional tickers\n",
    "ct_hashtags[\"ticker\"].replace({\"MBGn_other\": \"MBGn\", \"BMWG_other\": \"BMWG\", \"ADSGn_other\": \"ADSGn\", \"ADSGn_media\": \"ADSGn\"}, inplace=True)\n",
    "ct_hashtags.drop(columns=['author_location', 'username', 'tweet_id', 'media'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "bb0848a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_short = ct_hashtags.append(ct_cashtags, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "526c1ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187253"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ct_cashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "f4892195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7568280"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ct_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695fa7fb",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "193c3322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7755533"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ct_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "80c11ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7351585"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop exactly identical tweets\n",
    "ct_short = ct_short.drop_duplicates(subset=['text'])\n",
    "ct_short.reset_index(drop=True, inplace=True)\n",
    "len(ct_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "af7afbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_short[\"interaction\"] = ct_short[\"retweets\"]+ct_short[\"replies\"]+ct_short[\"likes\"]+ct_short[\"quote_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "14508f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3780169"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_short.drop(ct_short.loc[ct_short.interaction == 0].index, inplace=True)\n",
    "ct_short.reset_index(drop=True, inplace=True)\n",
    "len(ct_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "6ceb4f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3734840"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_short.drop(ct_short.loc[ct_short.author_account_age > '2020-09-18'].index, inplace=True)\n",
    "ct_short.reset_index(drop=True, inplace=True)\n",
    "len(ct_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "b74db417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3165026"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_short.drop(ct_short.loc[ct_short.author_followers < 100].index, inplace=True)\n",
    "ct_short.reset_index(drop=True, inplace=True)\n",
    "len(ct_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "6833d970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3155410"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_short.drop(ct_short.loc[ct_short.author_tweets < 100].index, inplace=True)\n",
    "ct_short.reset_index(drop=True, inplace=True)\n",
    "len(ct_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "e666f8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3130859"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_short.drop(ct_short.loc[ct_short.author_following == 0].index, inplace=True)\n",
    "ct_short.reset_index(drop=True, inplace=True)\n",
    "len(ct_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "a157fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tickers\n",
    "# ticker_list = [\"1COV\", \"BEIG\"]\n",
    "ticker_list = pd.unique(ct_short[\"ticker\"]).tolist()\n",
    "# for full list, change all names to unique tickers for Adidas, MB, VW, BMW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "198ff9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WDIG',\n",
       " 'VOWG_p',\n",
       " 'VNAn',\n",
       " 'TKAG',\n",
       " 'SIEGn',\n",
       " 'SAPG',\n",
       " 'RWEG',\n",
       " 'PSMGn',\n",
       " 'MUVGn',\n",
       " 'MTXGn',\n",
       " 'MRCG',\n",
       " 'MBGn',\n",
       " 'LINI',\n",
       " 'LHAG',\n",
       " 'IFXGn',\n",
       " 'HNKG_p',\n",
       " 'HEIG',\n",
       " 'FREG',\n",
       " 'FMEG',\n",
       " 'EONGn',\n",
       " 'ENR1n',\n",
       " 'DWNG',\n",
       " 'DTEGn',\n",
       " 'DPWGn',\n",
       " 'DHER',\n",
       " 'DBKGn',\n",
       " 'DB1Gn',\n",
       " 'CONG',\n",
       " 'CBKG',\n",
       " 'BMWG',\n",
       " 'BEIG',\n",
       " 'BAYGn',\n",
       " 'BASFn',\n",
       " 'ALVG',\n",
       " 'ADSGn',\n",
       " '1COV']"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "43c7abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "list_short = ct_short[\"text\"].apply(tweet_cleaning)\n",
    "# this is the cleanest data and will be used going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "5387fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates, i.e. each token appears only once\n",
    "list_single = list_short.copy()\n",
    "list_single = list_single.apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "0b2e5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten set\n",
    "list_single_flat = [item for sublist in list_single for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "bc7ec0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creates one list out of nested lists (flattens nested lists), needed to count items\n",
    "# list_short_flat = list_short.sum()\n",
    "# # count most common items\n",
    "# Counter(list_short_flat).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "7245251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creat bigrams and count\n",
    "# terms_bigram = bigrams(list_short_flat)\n",
    "# # Counter(terms_bigram).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88a8e4",
   "metadata": {},
   "source": [
    "# TBD: including bigrams instead of only single terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "6f2079f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create co-occurence matrix\n",
    "com = defaultdict(lambda : defaultdict(int))\n",
    "terms_only = []\n",
    "for x in range(len(list_short)):\n",
    "    terms_only = [term for term in list_short[x]]\n",
    "    \n",
    "    for i in range(len(terms_only)-1):            \n",
    "        for j in range(i+1, len(terms_only)):\n",
    "            w1, w2 = sorted([terms_only[i], terms_only[j]])                \n",
    "            if w1 != w2:\n",
    "                com[w1][w2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "dc13432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export co-occurence terms\n",
    "com_max = []\n",
    "# For each term, look for the most common co-occurrent terms\n",
    "for t1 in com:\n",
    "    t1_max_terms = sorted(com[t1].items(), key=operator.itemgetter(1), reverse=True)[:5]\n",
    "    for t2, t2_count in t1_max_terms:\n",
    "        com_max.append(((t1, t2), t2_count))\n",
    "# Get the most frequent co-occurrences\n",
    "# terms_max = sorted(com_max, key=operator.itemgetter(1), reverse=True)\n",
    "# print(terms_max[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "1fe2e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count single terms\n",
    "count_all = Counter()\n",
    "count_all.update(list_single_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "d3fabeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating probabilities\n",
    "# n_docs is the total n. of tweets\n",
    "n_docs = len(list_short)\n",
    "p_t = {}\n",
    "p_t_com = defaultdict(lambda : defaultdict(int))\n",
    " \n",
    "for term, n in count_all.items():\n",
    "    p_t[term] = n / n_docs\n",
    "    for t2 in com[term]:\n",
    "        p_t_com[term][t2] = com[term][t2] / n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "a8968319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vocab\n",
    "wb_pos = xlrd.open_workbook(\"dic_positive.xlsx\")\n",
    "ws_pos = wb_pos.sheet_by_index(0)\n",
    "positive_vocab = ws_pos.col_values(0)\n",
    "positive_vocab = [x.lower() for x in positive_vocab]\n",
    "wb_neg = xlrd.open_workbook(\"dic_negative.xlsx\")\n",
    "ws_neg = wb_neg.sheet_by_index(0)\n",
    "negative_vocab = ws_neg.col_values(0)\n",
    "negative_vocab = [x.lower() for x in negative_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "b0beb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # insert NLP dictionary\n",
    "# positive_vocab = [\n",
    "#     'good', 'nice', 'great', 'awesome', 'outstanding',\n",
    "#     'fantastic', 'terrific', ':)', ':-)', 'like', 'love',\n",
    "#     # shall we also include game-specific terms?\n",
    "#     # 'triumph', 'triumphal', 'triumphant', 'victory', etc.\n",
    "# ]\n",
    "# negative_vocab = [\n",
    "#     'bad', 'terrible', 'crap', 'useless', 'hate', ':(', ':-(',\n",
    "#     # 'defeat', etc.\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443da7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PMI\n",
    "pmi = defaultdict(lambda : defaultdict(int))\n",
    "for t1 in p_t:\n",
    "    for t2 in com[t1]:\n",
    "        denom = p_t[t1] * p_t[t2]\n",
    "        pmi[t1][t2] = math.log2(p_t_com[t1][t2] / denom)\n",
    " \n",
    "semantic_orientation = {}\n",
    "for term, n in p_t.items():\n",
    "    positive_assoc = sum(pmi[term][tx] for tx in positive_vocab)\n",
    "    negative_assoc = sum(pmi[term][tx] for tx in negative_vocab)\n",
    "    semantic_orientation[term] = positive_assoc - negative_assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show top and bottom PMI tokens\n",
    "semantic_sorted = sorted(semantic_orientation.items(), \n",
    "                         key=operator.itemgetter(1), \n",
    "                         reverse=True)\n",
    "# top_pos = semantic_sorted[:10]\n",
    "# top_neg = semantic_sorted[-10:]\n",
    " \n",
    "# print(top_pos)\n",
    "# print(top_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save PMI into df\n",
    "scores = pd.DataFrame(semantic_sorted, columns = ['token', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9abeb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nonzero = scores[scores['score'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nonzero.to_excel(\"scores_nonzero.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fe093",
   "metadata": {},
   "source": [
    "# TBD: removing all tokes with https://, coins etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "97d7e22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#id4</td>\n",
       "      <td>77.927454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awesome</td>\n",
       "      <td>67.350624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concept</td>\n",
       "      <td>65.676239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#jha</td>\n",
       "      <td>54.831341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#dtcmd18</td>\n",
       "      <td>53.630986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>artificial</td>\n",
       "      <td>49.144920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#china's</td>\n",
       "      <td>49.039119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#faw</td>\n",
       "      <td>48.670953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>overall</td>\n",
       "      <td>46.498405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>analytics</td>\n",
       "      <td>46.166089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bauxite</td>\n",
       "      <td>46.022104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>energy</td>\n",
       "      <td>44.829490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>#byd</td>\n",
       "      <td>44.670953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>#saic</td>\n",
       "      <td>44.670953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#electricvehicles</td>\n",
       "      <td>44.197061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>experience</td>\n",
       "      <td>43.868814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>#innovation</td>\n",
       "      <td>43.309537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>#vow</td>\n",
       "      <td>43.150733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>platform</td>\n",
       "      <td>42.594730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fundamentals</td>\n",
       "      <td>42.588063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                token      score\n",
       "0                #id4  77.927454\n",
       "1             awesome  67.350624\n",
       "2             concept  65.676239\n",
       "3                #jha  54.831341\n",
       "4            #dtcmd18  53.630986\n",
       "5          artificial  49.144920\n",
       "6            #china's  49.039119\n",
       "7                #faw  48.670953\n",
       "8             overall  46.498405\n",
       "9           analytics  46.166089\n",
       "10            bauxite  46.022104\n",
       "11             energy  44.829490\n",
       "12               #byd  44.670953\n",
       "13              #saic  44.670953\n",
       "14  #electricvehicles  44.197061\n",
       "15         experience  43.868814\n",
       "16        #innovation  43.309537\n",
       "17               #vow  43.150733\n",
       "18           platform  42.594730\n",
       "19       fundamentals  42.588063"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print top 20\n",
    "scores.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "86cd290c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34785</th>\n",
       "      <td>db</td>\n",
       "      <td>-234.150361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34786</th>\n",
       "      <td>fed</td>\n",
       "      <td>-234.679420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34787</th>\n",
       "      <td>billion</td>\n",
       "      <td>-236.108887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>another</td>\n",
       "      <td>-236.928835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>derivatives</td>\n",
       "      <td>-237.177665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34790</th>\n",
       "      <td>banking</td>\n",
       "      <td>-243.845325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34791</th>\n",
       "      <td>could</td>\n",
       "      <td>-246.733095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34792</th>\n",
       "      <td>assets</td>\n",
       "      <td>-255.613674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34793</th>\n",
       "      <td>case</td>\n",
       "      <td>-263.037148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34794</th>\n",
       "      <td>due</td>\n",
       "      <td>-265.071527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34795</th>\n",
       "      <td>credit</td>\n",
       "      <td>-268.228444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34796</th>\n",
       "      <td>business</td>\n",
       "      <td>-283.040391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34797</th>\n",
       "      <td>already</td>\n",
       "      <td>-286.060395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34798</th>\n",
       "      <td>bad</td>\n",
       "      <td>-307.530156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34799</th>\n",
       "      <td>#deutschebank</td>\n",
       "      <td>-322.306571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34800</th>\n",
       "      <td>capital</td>\n",
       "      <td>-362.555356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34801</th>\n",
       "      <td>deutsche</td>\n",
       "      <td>-386.594162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34802</th>\n",
       "      <td>amp</td>\n",
       "      <td>-451.244405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34803</th>\n",
       "      <td>banks</td>\n",
       "      <td>-536.999239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34804</th>\n",
       "      <td>bank</td>\n",
       "      <td>-627.593585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token       score\n",
       "34785             db -234.150361\n",
       "34786            fed -234.679420\n",
       "34787        billion -236.108887\n",
       "34788        another -236.928835\n",
       "34789    derivatives -237.177665\n",
       "34790        banking -243.845325\n",
       "34791          could -246.733095\n",
       "34792         assets -255.613674\n",
       "34793           case -263.037148\n",
       "34794            due -265.071527\n",
       "34795         credit -268.228444\n",
       "34796       business -283.040391\n",
       "34797        already -286.060395\n",
       "34798            bad -307.530156\n",
       "34799  #deutschebank -322.306571\n",
       "34800        capital -362.555356\n",
       "34801       deutsche -386.594162\n",
       "34802            amp -451.244405\n",
       "34803          banks -536.999239\n",
       "34804           bank -627.593585"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print bottom 20\n",
    "scores.tail(20)\n",
    "# why do $db and $DB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "09fd83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize\n",
    "vectorizer = CountVectorizer(analyzer = tweet_cleaning, dtype = 'uint8')\n",
    "tweets_countvectorizer = vectorizer.fit_transform(ct_short[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "759106d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scores for each tweet\n",
    "vectorizer_tokens = vectorizer.get_feature_names()\n",
    "vectorizer_tokens = pd.DataFrame(vectorizer_tokens, columns = ['token'])\n",
    "combined = pd.merge(vectorizer_tokens, scores, on=\"token\", how=\"left\")\n",
    "# fill potential NaN with zero\n",
    "combined['score'] = combined['score'].fillna(0)\n",
    "combined = combined['score'].drop(columns=['token'])\n",
    "# b = np.array(combined)\n",
    "b = np.matrix(combined).transpose()\n",
    "c = (tweets_countvectorizer *b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "e1c91998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tweets_countvectorizer.toarray()\n",
    "# c = a*b\n",
    "# c = np.sum(c, axis=1)\n",
    "# # print scores and tokens\n",
    "# print(scores.score.to_string())\n",
    "# print(scores.token.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ce2f9d",
   "metadata": {},
   "source": [
    "# Combining scores with date and ticker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "d544aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only date, ticker, and score\n",
    "tweets_scored = ct_short[['created_at', 'ticker']].copy()\n",
    "sum_score = pd.DataFrame(c)\n",
    "tweets_scored[\"score\"] = sum_score.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "d79c8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by date and ticker \n",
    "# https://stackoverflow.com/questions/35898667/group-by-time-and-other-column-in-pandas\n",
    "tweets_scored['date'] = pd.to_datetime(tweets_scored['created_at'])\n",
    "tweets_scored.index = tweets_scored['date']\n",
    "tweets_scored_bydate = tweets_scored.groupby([pd.Grouper(freq='D'), \"ticker\"]).mean()\n",
    "# # this creates multiindex\n",
    "# tweets_scored_bydate.index\n",
    "# tweets_scored_bydate.index.nlevels\n",
    "# https://stackoverflow.com/questions/49395100/change-pandas-multi-index-from-row-to-column\n",
    "tweets_scored_bydate = tweets_scored_bydate.unstack()\n",
    "tweets_scored_bydate.columns = tweets_scored_bydate.columns.droplevel(0)\n",
    "# print(tweets_scored_bydate.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "821955f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_scored_bydate.loc[\"2018-02-19\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "b7aeb46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with all dates for subsequent calcs\n",
    "all_dates = pd.date_range(start=\"2016-01-01\",end=\"2021-12-31\")\n",
    "all_dates_df = pd.DataFrame(all_dates, columns=[\"date\"])\n",
    "all_dates_df.index = all_dates_df['date']\n",
    "#all_dates_df[\"all_dates\"] = all_dates_df['date'] # not needed\n",
    "all_dates_df = all_dates_df.drop('date', 1)\n",
    "#all_dates_df[\"ticker\"] = \"\" # not needed\n",
    "#print(all_dates_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "7732c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create multiindex for second df\n",
    "# all_dates_df['ticker'] = ''\n",
    "# all_dates_df.set_index('ticker', append=True, inplace=True)\n",
    "# all_dates_df.index.nlevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "bdc1cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge into one and fill NaN\n",
    "scoring = pd.merge(all_dates_df, tweets_scored_bydate, on=[\"date\"], how=\"left\")\n",
    "scoring = scoring.fillna(0)\n",
    "scoring[\"decay_factor\"] = 0.9\n",
    "#print(scoring.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "66f8b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring.loc[\"2018-02-19\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23ce1d",
   "metadata": {},
   "source": [
    "# Calculate EWA scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "d3748f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate the last Friday per month for rebalancing\n",
    "# def rebalancing_dates():\n",
    "#     fridays = []\n",
    "#     for year in range (2016, 2022):\n",
    "#         for month in range(1, 13):\n",
    "#             last_friday = max(week[calendar.FRIDAY]\n",
    "#                 for week in calendar.monthcalendar(year, month))\n",
    "#             fridays.append(str('{:4d}-{:02d}-{:02d}'.format(year, month, last_friday)))\n",
    "#     return fridays\n",
    "# #rebalancing_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "11ebfac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 3rd Friday each month\n",
    "friday3_list = pd.date_range('2016-01-01','2021-12-31',freq='WOM-3FRI').format()\n",
    "# friday3_df = pd.DataFrame(friday3_list)\n",
    "# friday3_df.to_csv('rebalancing_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "06ee1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19.04.2019 not a trading day, \"Karfreitag\", now moved to next weekday, which is Tuesday\n",
    "friday3_list[friday3_list.index(\"2019-04-19\")] = '2019-04-23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "b8f89f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate EWA as per S&P methodology\n",
    "ewa = pd.DataFrame(friday3_list, columns=[\"date\"])\n",
    "ewa[\"next_rb\"] = ewa[\"date\"].copy()\n",
    "ewa[\"last_rb\"] = ewa[\"next_rb\"].copy()\n",
    "ewa[\"last_rb\"] = ewa[\"last_rb\"].shift(+1)\n",
    "ewa[\"next_rb\"] = pd.to_datetime(ewa[\"next_rb\"])\n",
    "ewa[\"last_rb\"] = pd.to_datetime(ewa[\"last_rb\"])\n",
    "ewa[\"N\"] = abs((ewa[\"last_rb\"] - ewa[\"next_rb\"]).dt.days)\n",
    "ewa.drop(ewa.tail(1).index,inplace=True)\n",
    "ewa['date'] = pd.to_datetime(ewa['date'])\n",
    "ewa.index = ewa['date']\n",
    "# drop second date column\n",
    "ewa = ewa.drop('date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "bd393145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewa.to_excel(\"00_ewa.xlsx\")\n",
    "# scoring.to_excel(\"00_scoring.xlsx\")\n",
    "# scoring_ewa.to_excel(\"00_scoring_ewa.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "4cc458d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate alpha\n",
    "scoring_ewa = pd.merge_asof(scoring, ewa, on='date', direction='forward')\n",
    "scoring_ewa[\"t\"] = abs(((scoring_ewa[\"next_rb\"] - scoring_ewa[\"date\"]).dt.days) - scoring_ewa[\"N\"])\n",
    "scoring_ewa[\"a\"] = (scoring_ewa[\"decay_factor\"]**(scoring_ewa[\"N\"] - scoring_ewa[\"t\"]))\n",
    "#print(scoring_ewa.to_string())\n",
    "scoring_ewa.index = scoring_ewa[\"date\"]\n",
    "scoring_ewa['rb'] = np.where(scoring_ewa['date']==scoring_ewa['next_rb'], True, False)\n",
    "# drop second date column\n",
    "scoring_ewa = scoring_ewa.drop('date', 1)\n",
    "scoring_ewa = scoring_ewa[scoring_ewa['t'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "1af2b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(scoring_ewa.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "2d50e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply all ticker columns by column a\n",
    "scoring_ewa_a = scoring_ewa.copy()\n",
    "scoring_ewa_a = scoring_ewa.apply(lambda x: x*scoring_ewa[\"a\"] if x.name in ticker_list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "f8762913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring_ewa_a.to_excel(\"00_scoring_ewa_a.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "1c583681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(scoring_ewa_a.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "7938cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extend to all columns\n",
    "# # https://stackoverflow.com/questions/48103845/python-pandas-sum-values-in-columns-if-date-between-2-dates\n",
    "# scoring_ewa[\"sum\"] = scoring_ewa.apply(lambda x: scoring_ewa.loc[(scoring_ewa.index >= x.last_rb) & \n",
    "#                                             (scoring_ewa.index <= x.next_rb), \"1COV\"].sum(), axis=1)\n",
    "# # maybe create a new file with just the rebalancing dates? maybe easier for index calculation?\n",
    "# # may need a matrix of 0 and 1 in the end for each date and/or each trading date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "ced3c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works on all columns, replacing original values\n",
    "# https://stackoverflow.com/questions/48103845/python-pandas-sum-values-in-columns-if-date-between-2-dates\n",
    "scoring_ewa_sum = scoring_ewa_a.copy()\n",
    "scoring_ewa_sum[ticker_list] = scoring_ewa_sum.apply(lambda x: scoring_ewa_sum.loc[(scoring_ewa_sum.index > x.last_rb) & \n",
    "                                            (scoring_ewa_sum.index <= x.next_rb), ticker_list].sum(), axis=1)\n",
    "# maybe create a new file with just the rebalancing dates? maybe easier for index calculation?\n",
    "# may need a matrix of 0 and 1 in the end for each date and/or each trading date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "28becc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring_ewa_sum.to_excel(\"00_scoring_ewa_sum.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "a188ff09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(scoring_ewa_sum.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "d24f63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only rows where rb = TRUE\n",
    "scoring_ewa_rb = scoring_ewa_sum[scoring_ewa_sum['rb'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "440053ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(scoring_ewa_rb.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "b9f87f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only data columns\n",
    "ewa_data = scoring_ewa_rb[np.intersect1d(scoring_ewa_rb.columns, ticker_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "0b5b22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewa_data.to_excel(\"00_ewa_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "c05510ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ewa_data[\"1COV\"].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199dd4af",
   "metadata": {},
   "source": [
    "# Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "93cc0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out companies not in benchmark\n",
    "# multiply by matrix of zero and 1\n",
    "xls = pd.ExcelFile('daxk_data.xlsx')\n",
    "ticker_matrix_daxk = pd.read_excel(xls, 'ticker_matrix')\n",
    "ticker_matrix_daxk.set_index(ticker_matrix_daxk.columns[0], inplace=True)\n",
    "ticker_matrix_daxk.index = pd.to_datetime(ticker_matrix_daxk.index)\n",
    "# isin_list = pd.read_excel(xls, 'isin_list')\n",
    "ticker_to_isin = pd.read_excel(xls, 'ticker_to_isin')\n",
    "isin_shell = pd.read_excel(xls, 'isin_shell')\n",
    "isin_shell.set_index(isin_shell.columns[0], inplace=True)\n",
    "isin_shell.index = pd.to_datetime(isin_shell.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "3154f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewa_data_nn = ewa_data.copy()\n",
    "ewa_data_nn = ewa_data_nn.rename(columns=(ticker_to_isin.set_index('primary_ticker')['ISIN'].to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "27e71cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewa_data_nn.drop(ewa_data_nn.loc[ewa_data_nn.index > '2021-09-17'].index, inplace=True)\n",
    "ewa_data_nn.drop(ewa_data_nn.loc[ewa_data_nn.index < '2016-09-12'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "da3b95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rb_dates = ewa_data_nn.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "d5e56bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dates\n",
    "ticker_matrix_daxk_shortd = ticker_matrix_daxk[ticker_matrix_daxk.index.isin(ewa_data_nn.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "3ea8ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ticker_matrix_daxk_shortd[\"DE000CBK1001\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "8f491dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns\n",
    "ticker_matrix_daxk_shortc = ticker_matrix_daxk[ticker_matrix_daxk.columns[ticker_matrix_daxk.columns.isin(ewa_data_nn.columns)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "e4f97987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dates and columns\n",
    "ticker_matrix_daxk_shortd_shortc = ticker_matrix_daxk_shortd[ticker_matrix_daxk_shortd.columns[ticker_matrix_daxk_shortd.columns.isin(ewa_data_nn.columns)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "43028de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_matrix_daxk_shortshort.to_csv('ticker_matrix_daxk_shortd_shortc.csv')\n",
    "# ewa_data_nn.to_csv('ewa_data_nn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "012fff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ticker_matrix_daxk_shortd_shortc[\"DE0006062144\"].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05953c",
   "metadata": {},
   "source": [
    "# Check here for correct companies: Covestro/Pro7, Wirecard/Combank, SiemensE/Beiersdorf etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "5915c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd offsetting ising matrix by 1? i.e. Wirecad included as per 24.09.2018\n",
    "# i.e. matrix is 0 on Friday 21.09. but included from Monday on\n",
    "# does this hold for exclusions too? i.e. check Commerzbank kicked out\n",
    "data_np = ticker_matrix_daxk_shortd_shortc*ewa_data_nn\n",
    "# print(data_np[\"DE0007472060\"].to_string())\n",
    "# turn isin matrix values into NaN not zero through multiplication by multiplying by NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "78530c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_np.to_excel(\"00_data_np.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "4cc33aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_np[\"DE0007472060\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "93298b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # same as ewa_data\n",
    "# print(data_np[\"DE0006062144\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "e04effc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewa_data_np = data_np.to_numpy()\n",
    "# data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "da1179cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_np[\"DE0007472060\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "2119d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_np[\"DE000CBK1001\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "cecf8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_np[36]\n",
    "# zscore(data_np[36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "ad3b5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.isfinite(data_np).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "5640628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute z-scores across companies\n",
    "ewa_data_zscore = zscore(ewa_data_np,axis=1,nan_policy='omit', ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "7f624f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform z-scores to make all positive\n",
    "ewa_data_zscore = np.where(ewa_data_zscore<0,(1/(1-ewa_data_zscore)),(ewa_data_zscore+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "2699c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into dataframe\n",
    "df_ewa_data_zscore = pd.DataFrame(ewa_data_zscore, columns = data_np.columns)\n",
    "df_ewa_data_zscore.index = data_np.index\n",
    "# print(df_ewa_data_zscore[\"DE0007472060\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "b5fc1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ewa_data_zscore.to_excel(\"00_df_ewa_data_zscore.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "e9828235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_ewa_data_zscore[\"DE0007472060\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "2e6cfb73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(df_ewa_data_zscore[\"DE0007472060\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "00479942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_ewa_data_zscore[\"DE0006062144\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "e2bfd385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_ewa_data_zscore[\"DE0005190003\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "6ead4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_matrix.loc[\"2018-09-21\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "adb92827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checks for median, also works with other cut offs\n",
    "# ticker_matrix = df_ewa_data_zscore.gt(df_ewa_data_zscore.median(axis=1), axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "5e4df275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-largest\n",
    "ticker_matrix = df_ewa_data_zscore.apply(pd.Series.nlargest, axis=1, n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "cd2a0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_matrix.to_excel(\"00_ticker_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "1635caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_matrix = ticker_matrix.fillna(0)\n",
    "ticker_matrix[ticker_matrix > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "820e7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dates\n",
    "isin_shell_shortd = isin_shell[isin_shell.index.isin(ewa_data_nn.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "7c78827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns\n",
    "isin_shell_shortc = isin_shell[isin_shell.columns[~isin_shell.columns.isin(isin_shell.columns)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "e522b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns not in ticker_matrix but in the shell\n",
    "# isin_shell_shortd.columns[~isin_shell_shortd.columns.isin(ticker_matrix.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "76c3593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_matrix_shortd = pd.merge(ticker_matrix, isin_shell[isin_shell_shortd.columns[~isin_shell_shortd.columns.isin(ticker_matrix.columns)]], on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "0aacea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ticker_matrix_shortd[\"DE0006062144\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "9cd3ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_matrix_full = pd.merge_asof(isin_shell_shortc, ticker_matrix_shortd, on='date', direction='backward', allow_exact_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "85a66b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_matrix_full.set_index(ticker_matrix_full.columns[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "57ef853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ticker_matrix_shortd[\"DE0007472060\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "f0c34acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ticker_matrix_shortd[\"DE0006062144\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "674aa341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ticker_matrix_full[\"DE0006062144\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "9198b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 1 for all companies included from 19.09.2016 onwards\n",
    "ticker_matrix_full.loc[ticker_matrix_full.index == '2016-09-12'] = 1\n",
    "ticker_matrix_full.loc[ticker_matrix_full.index == '2016-09-13'] = 1\n",
    "ticker_matrix_full.loc[ticker_matrix_full.index == '2016-09-14'] = 1\n",
    "ticker_matrix_full.loc[ticker_matrix_full.index == '2016-09-15'] = 1\n",
    "ticker_matrix_full.loc[ticker_matrix_full.index == '2016-09-16'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "1ed509cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_matrix_full.index = pd.to_datetime(ticker_matrix_full.index)\n",
    "ticker_matrix_full = ticker_matrix_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "4f03312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_matrix.to_csv('ticker_matrix.csv')\n",
    "ticker_matrix_full.to_csv('ticker_matrix_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572770e",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "739ec776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # EXAMPLE\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame({'data': [5, 10, 20, 25, 20, 24, 16, 12],\n",
    "#                    'next': ['2021-02-26', '2021-02-26', '2021-02-26', '2021-03-26', '2021-03-26', '2021-03-26', '2021-03-26', '2021-03-26'],\n",
    "#                    'last': ['2020-01-29', '2020-01-29', '2020-01-29', '2021-02-26', '2021-02-26', '2021-02-26', '2021-02-26', '2021-02-26'],\n",
    "#                    't': [26, 27, 28, 1, 2, 3, 4, 5],\n",
    "#                    'expected_sum': [\"NaN\", \"NaN\", \"NaN\", 25, 45, 69, 85, 97]},\n",
    "#                 index = ['2021-02-24', '2021-02-25', '2021-02-26', '2021-02-27', '2021-02-28', '2021-03-01', '2021-03-02', '2021-03-03'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "c9de9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXAMPLE\n",
    "# import pandas as pd\n",
    "# df_input = pd.DataFrame({'row1': [5, 10, 20], 'row2': [1, 30, 40],},\n",
    "#                         index = ['2021-02-24', '2021-02-25', '2021-02-26'])\n",
    "# df_expected_output = pd.DataFrame({'row1': [1, 0, 0], 'row2': [0, 1, 1],},\n",
    "#                         index = ['2021-02-24', '2021-02-25', '2021-02-26'])\n",
    "# df_median = df_input.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "30e40452",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_obs = np.array([[ 0.8413,  0.8740,  0.3426,  0.8064],\n",
    "              [ 0.9417,  0.5770,  0.2706,  0.6569],\n",
    "              [ 0.1436,  0.3041,  0.9579,  0.4604],\n",
    "              [ 0.8195,  0.8496,  0.409 ,  0.1273],\n",
    "              [ 0.1290,  0.1842,  0.8811,  0.6631]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "b048702e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8413, 0.874 , 0.3426, 0.8064],\n",
       "       [0.9417, 0.577 , 0.2706, 0.6569],\n",
       "       [0.1436, 0.3041, 0.9579, 0.4604],\n",
       "       [0.8195, 0.8496, 0.409 , 0.1273],\n",
       "       [0.129 , 0.1842, 0.8811, 0.6631]])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f3a27009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8413],\n",
       "       [0.9417],\n",
       "       [0.1436],\n",
       "       [0.8195],\n",
       "       [0.129 ]])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column\n",
    "array_obs[:,[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "87a7709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8413, 0.874 , 0.3426, 0.8064])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row \n",
    "array_obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "31ca911c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5772150421492275"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis = 1 is equal to rowise\n",
    "(array_obs[0][0] - array_obs[0].mean())/array_obs[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "99245f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57721504,  0.72794319, -1.7215044 ,  0.41634617],\n",
       "       [ 1.38134372, -0.14455679, -1.4265308 ,  0.18974387],\n",
       "       [-1.05861834, -0.53242372,  1.61104073, -0.01999867],\n",
       "       [ 0.89266939,  0.99287207, -0.47388211, -1.41165936],\n",
       "       [-1.05504269, -0.88137829,  1.31113476,  0.62528622]])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zscore(array_obs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "18ddeb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7384217501663388"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis = 0\n",
    "(array_obs[0][0] - array_obs[:,[0]].mean())/array_obs[:,[0]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "1515fb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73842175,  1.1330645 , -0.79757591,  1.12104701],\n",
       "       [ 1.01684125,  0.06886819, -1.04764325,  0.4852001 ],\n",
       "       [-1.19637191, -0.90897414,  1.33945795, -0.35054517],\n",
       "       [ 0.67796811,  1.04563558, -0.56695824, -1.76727163],\n",
       "       [-1.2368592 , -1.33859413,  1.07271945,  0.51156967]])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zscore(array_obs) # default is 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
